--SQL CODE
1.
select product_id
from products
where low_fats = 'Y' and recyclable = 'Y';

from pyspark.sql import SparkSession

--PYSPARK CODE
# Initialize Spark session
spark = SparkSession.builder.appName("ProductFilter").getOrCreate()

# Load the data into a DataFrame
products_df = spark.read.csv("path_to_products.csv", header=True, inferSchema=True)

# Filter the DataFrame
filtered_df = products_df.filter((products_df.low_fats == 'Y') & (products_df.recyclable == 'Y'))

# Select the product_id column
result_df = filtered_df.select("product_id")

# Show the result
result_df.show()

2.
--SQL CODE
select name
from customer
where referee_id is null or referee_id <> 2;

--PYSPARK CODE
from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("CustomerFilter").getOrCreate()

# Load the data into a DataFrame
customer_df = spark.read.csv("path_to_customer.csv", header=True, inferSchema=True)

# Filter the DataFrame
filtered_df = customer_df.filter((customer_df.referee_id.isNull()) | (customer_df.referee_id != 2))

# Select the name column
result_df = filtered_df.select("name")

# Show the result
result_df.show()

3.
--SQL CODE
select name, population, area
from world
where area >= 3000000 or population >= 25000000;

--PYSPARK CODE
from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("WorldFilter").getOrCreate()

# Load the data into a DataFrame
world_df = spark.read.csv("path_to_world.csv", header=True, inferSchema=True)

# Filter the DataFrame
filtered_df = world_df.filter((world_df.area >= 3000000) | (world_df.population >= 25000000))

# Select the name, population, and area columns
result_df = filtered_df.select("name", "population", "area")

# Show the result
result_df.show()

4.
--SQL CODE
select * from (
select distinct author_id as id
from views
where author_id = viewer_id
)
order by id;

--PYSPARK CODE
from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("AuthorFilter").getOrCreate()

# Load the data into a DataFrame
views_df = spark.read.csv("path_to_views.csv", header=True, inferSchema=True)

# Filter and select distinct author_id where author_id equals viewer_id
distinct_df = views_df.filter(views_df.author_id == views_df.viewer_id).select("author_id").distinct()

# Rename the column to id
distinct_df = distinct_df.withColumnRenamed("author_id", "id")

# Order by id
result_df = distinct_df.orderBy("id")

# Show the result
result_df.show()

5.
--SQL CODE

